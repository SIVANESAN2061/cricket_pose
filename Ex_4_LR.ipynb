{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mc-QS5KwJOzx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Replace this with your actual dataset loading logic\n",
        "def load_dataset(dataset_path):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for class_index, folder_name in enumerate(os.listdir(dataset_path)):\n",
        "        folder_path = os.path.join(dataset_path, folder_name)\n",
        "\n",
        "        if os.path.isdir(folder_path):\n",
        "            for filename in os.listdir(folder_path):\n",
        "                image_path = os.path.join(folder_path, filename)\n",
        "                image = cv2.imread(image_path)\n",
        "\n",
        "                if image is not None:\n",
        "                    # Resize images to a consistent size if needed\n",
        "                    image = cv2.resize(image, (width, height))  # Set your desired width and height\n",
        "                    images.append(image)\n",
        "                    labels.append(class_index)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load the dataset\n",
        "dataset_path = \"/content/drive/MyDrive/data\"  # Replace with your dataset path\n",
        "width, height = 64, 64  # Set your desired width and height\n",
        "X, y = load_dataset(dataset_path)\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "K2fenramMBkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print shapes for debugging\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"X_val shape:\", X_val.shape)\n",
        "print(\"y_val shape:\", y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NXg_nQDilwl",
        "outputId": "3c48dce5-e280-4e00-fe2d-8863d89d5a30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (5434, 64, 64, 3)\n",
            "y_train shape: (5434,)\n",
            "X_val shape: (1359, 64, 64, 3)\n",
            "y_val shape: (1359,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Replace this with your actual model training logic\n",
        "def train_model(X_train, y_train, X_val, y_val, epochs):\n",
        "    model = LogisticRegression(max_iter=500)  # Increase max_iter if needed\n",
        "    accuracy_history = []\n",
        "\n",
        "    if X_train.shape[0] == 0 or X_val.shape[0] == 0:\n",
        "        print(\"No training or validation samples found. Check your dataset.\")\n",
        "        return accuracy_history\n",
        "\n",
        "    # Reshape input data to 2D\n",
        "    X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
        "    X_val_flat = X_val.reshape(X_val.shape[0], -1)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train_flat, y_train)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Use the validation set for accuracy calculation\n",
        "        val_accuracy = model.score(X_val_flat, y_val)\n",
        "        accuracy_history.append(val_accuracy)\n",
        "\n",
        "    return accuracy_history\n",
        "\n",
        "\n",
        "# Train the model\n",
        "epochs = 10  # Set the number of epochs\n",
        "history = train_model(X_train, y_train, X_val, y_val, epochs)\n",
        "\n",
        "# Print the accuracy history\n",
        "print(\"Accuracy History:\")\n",
        "for epoch, acc in enumerate(history):\n",
        "    print(f\"Epoch {epoch + 1}: {acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ico1SHBHSIox",
        "outputId": "fadbbe4a-ec21-4dfc-e05d-410b37ada355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Validation Accuracy: 0.39661515820456217\n",
            "Epoch 2/10, Validation Accuracy: 0.39661515820456217\n",
            "Epoch 3/10, Validation Accuracy: 0.39661515820456217\n",
            "Epoch 4/10, Validation Accuracy: 0.39661515820456217\n",
            "Epoch 5/10, Validation Accuracy: 0.39661515820456217\n",
            "Epoch 6/10, Validation Accuracy: 0.39661515820456217\n",
            "Epoch 7/10, Validation Accuracy: 0.39661515820456217\n",
            "Epoch 8/10, Validation Accuracy: 0.39661515820456217\n",
            "Epoch 9/10, Validation Accuracy: 0.39661515820456217\n",
            "Epoch 10/10, Validation Accuracy: 0.39661515820456217\n",
            "Accuracy History:\n",
            "Epoch 1: 0.39661515820456217\n",
            "Epoch 2: 0.39661515820456217\n",
            "Epoch 3: 0.39661515820456217\n",
            "Epoch 4: 0.39661515820456217\n",
            "Epoch 5: 0.39661515820456217\n",
            "Epoch 6: 0.39661515820456217\n",
            "Epoch 7: 0.39661515820456217\n",
            "Epoch 8: 0.39661515820456217\n",
            "Epoch 9: 0.39661515820456217\n",
            "Epoch 10: 0.39661515820456217\n"
          ]
        }
      ]
    }
  ]
}